{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0531c994-79e7-4274-8603-0b0b92de01ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b40e0754-fec6-4f28-9165-23e196f6653a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = '''\n",
    "Stemming in NLTK (Natural Language Toolkit) is a vital technique used in natural language processing to reduce words to their base or root form. By stripping suffixes and prefixes, stemming helps to unify different forms of a word, allowing models to treat them as equivalent. For example, the words \"running,\" \"runner,\" and \"ran\" may all be stemmed to \"run.\" This normalization process is crucial for tasks like text classification, sentiment analysis, and information retrieval, as it reduces dimensionality and enhances the model's ability to recognize related terms.\n",
    "\n",
    "In NLTK, stemming can be easily implemented using classes like PorterStemmer or LancasterStemmer. By applying these stemmers to a corpus of text, you can preprocess your data to improve the performance of machine learning algorithms. The effectiveness of stemming is particularly evident in applications such as search engines, where users might input variations of a word. By stemming the query and the documents in the database, the system can return more relevant results, ensuring that variations of a word lead to comprehensive matches.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c00d02e8-4f3c-4852-856d-cbc9b361baf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a2cd51a-2a80-424e-b1ce-e8ca9c647666",
   "metadata": {
    "panel-layout": {
     "height": 27.135417938232422,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ambig\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "443f11cd-9e34-47f3-a975-45f186ad4769",
   "metadata": {
    "panel-layout": {
     "height": 3116.4375,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fcc68e2-da35-46cd-850b-b635ce90a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83b80c1e-950c-4d2d-a2b3-580993576e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences= nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eab70ca4-6235-4d38-ad3b-58cb587f8d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [stemmer.stem(word) for word in words if word.lower() not in set(stopwords.words('english'))]\n",
    "    sentences[i] = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "023f6a2e-1847-4621-98c0-d6ce9e2851c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stem nltk ( natur languag toolkit ) vital techniqu use natur languag process reduc word base root form .',\n",
       " 'strip suffix prefix , stem help unifi differ form word , allow model treat equival .',\n",
       " \"exampl , word `` run , '' `` runner , '' `` ran '' may stem `` run . ''\",\n",
       " \"normal process crucial task like text classif , sentiment analysi , inform retriev , reduc dimension enhanc model 's abil recogn relat term .\",\n",
       " 'nltk , stem easili implement use class like porterstemm lancasterstemm .',\n",
       " 'appli stemmer corpu text , preprocess data improv perform machin learn algorithm .',\n",
       " 'effect stem particularli evid applic search engin , user might input variat word .',\n",
       " 'stem queri document databas , system return relev result , ensur variat word lead comprehens match .']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c8115f5-f039-4dd5-a1e8-bd66a82421ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowballstemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97237b20-717e-4081-82c8-890d2f8cb1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [snowballstemmer.stem(word) for word in words if word.lower() not in set(stopwords.words('english'))]\n",
    "    sentences[i] = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe1677f2-786d-4b1a-921d-c7ab2e37f9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stem nltk ( natur languag toolkit ) vital techniqu use natur languag process reduc word base root form .',\n",
       " 'strip suffix prefix , stem help unifi differ form word , allow model treat equiv .',\n",
       " 'exampl , word `` run , `` `` runner , `` `` ran `` may stem `` run . ``',\n",
       " \"normal process crucial task like text classif , sentiment analysi , inform retriev , reduc dimens enhanc model 's abil recogn relat term .\",\n",
       " 'nltk , stem easili implement use class like porterstemm lancasterstemm .',\n",
       " 'appli stemmer corpu text , preprocess data improv perform machin learn algorithm .',\n",
       " 'effect stem particular evid applic search engin , user might input variat word .',\n",
       " 'stem queri document databa , system return relev result , ensur variat word lead comprehen match .']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27df1f7-7bc4-4d89-bf90-ce01e35a32c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "panel-cell-order": [
   "4a2cd51a-2a80-424e-b1ce-e8ca9c647666",
   "443f11cd-9e34-47f3-a975-45f186ad4769"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
